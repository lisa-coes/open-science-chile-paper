@misc{arslan_chain_2025,
  title = {Chain Simple Forms / Surveys into Longer Runs Using the Power of {{R}} to Generate Pretty Feedback and Complex Designs {{https://formr.org}}},
  shorttitle = {Chain Simple Forms / Surveys into Longer Runs Using the Power of {{R}} to Generate Pretty Feedback and Complex Designs Https},
  author = {Arslan, Ruben C. and Tata, Cyril},
  year = {2025},
  month = feb,
  doi = {10.5281/zenodo.14832648},
  urldate = {2025-02-17},
  abstract = {Fixes it wasn't possible to specify a maximal file size for audio/video uploads},
  howpublished = {Zenodo}
}

@article{arslan_formr_2020,
  title = {Formr: {{A}} Study Framework Allowing for Automated Feedback Generation and Complex Longitudinal Experience-Sampling Studies Using {{R}}},
  shorttitle = {Formr},
  author = {Arslan, Ruben C. and Walther, Matthias P. and Tata, Cyril S.},
  year = {2020},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {52},
  number = {1},
  pages = {376--387},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01236-y},
  urldate = {2025-02-17},
  abstract = {Open-source software improves the reproducibility of scientific research. Because existing open-source tools often do not offer dedicated support for longitudinal data collection on phones and computers, we built formr, a study framework that enables researchers to conduct both simple surveys and more intricate studies. With automated email and text message reminders that can be sent according to any schedule, longitudinal and experience-sampling studies become easy to implement. By integrating a web-based application programming interface for the statistical programming language R via OpenCPU, formr allows researchers to use a familiar programming language to enable complex features. These can range from adaptive testing, to graphical and interactive feedback, to integration with non-survey data sources such as self-trackers or online social network data. Here we showcase three studies created in formr: a study of couples with dyadic feedback; a longitudinal study over months, which included social networks and peer and partner ratings; and a diary study with daily invitations sent out by text message and email and extensive feedback on intraindividual patterns.},
  langid = {english},
  keywords = {Feedback,Online,R,Study,Survey,Web}
}

@article{baker_1500_2016,
  title = {1,500 Scientists Lift the Lid on Reproducibility},
  author = {Baker, Monya},
  year = {2016},
  month = may,
  journal = {Nature},
  volume = {533},
  number = {7604},
  pages = {452--454},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/533452a},
  urldate = {2021-12-05},
  langid = {english}
}

@article{banks_answers_2019,
  title = {Answers to 18 {{Questions About Open Science Practices}}},
  author = {Banks, George C. and Field, James G. and Oswald, Frederick L. and O'Boyle, Ernest H. and Landis, Ronald S. and Rupp, Deborah E. and Rogelberg, Steven G.},
  year = {2019},
  month = jun,
  journal = {Journal of Business and Psychology},
  volume = {34},
  number = {3},
  pages = {257--270},
  issn = {0889-3268, 1573-353X},
  doi = {10.1007/s10869-018-9547-8},
  urldate = {2025-06-19},
  langid = {english}
}

@book{bezjak_open_2018,
  title = {Open {{Science Training Handbook}}},
  author = {Bezjak, Sonja and {Clyburne-Sherin}, April and Conzett, Philipp and Fernandes, Pedro and G{\"o}r{\"o}gh, Edit and Helbig, Kerstin and Kramer, Bianca and Labastida, Ignasi and Niemeyer, Kyle and Psomopoulos, Fotis and {Ross-Hellauer}, Tony and Schneider, Ren{\'e} and Tennant, Jon and Verbakel, Ellen and Brinken, Helene and Heller, Lambert},
  year = {2018},
  month = apr,
  publisher = {Zenodo},
  doi = {10.5281/ZENODO.1212496},
  urldate = {2025-06-19},
  abstract = {{$<$}strong{$>$}For a readable version of the book, please visit https://book.fosteropenscience.eu{$<$}/strong{$>$} A group of fourteen authors came together in February 2018 at the TIB (German National Library of Science and Technology) in Hannover to create an open, living handbook on Open Science training. High-quality trainings are fundamental when aiming at a cultural change towards the implementation of Open Science principles. Teaching resources provide great support for Open Science instructors and trainers. The Open Science training handbook will be a key resource and a first step towards developing Open Access and Open Science curricula and andragogies. Supporting and connecting an emerging Open Science community that wishes to pass on their knowledge as multipliers, the handbook will enrich training activities and unlock the community's full potential. In this first release of the Open Science Training Handbook, some initial feedback from the community is already included.},
  copyright = {Creative Commons Zero - CC0 1.0, Open Access},
  langid = {english},
  keywords = {Open Science,Training,Translational skills,Vocational training}
}

@book{boyatzis_transforming_2010,
  title = {Transforming Qualitative Information: Thematic Analysis and Code Development},
  shorttitle = {Transforming Qualitative Information},
  author = {Boyatzis, Richard E.},
  year = {2010},
  publisher = {Sage},
  address = {Thousand Oaks, Calif.},
  isbn = {978-0-7619-0961-3},
  langid = {english}
}

@article{braun_using_2006,
  title = {Using Thematic Analysis in Psychology},
  author = {Braun, Virginia and Clarke, Victoria},
  year = {2006},
  month = jan,
  journal = {Qualitative Research in Psychology},
  volume = {3},
  number = {2},
  pages = {77--101},
  issn = {1478-0887, 1478-0895},
  doi = {10.1191/1478088706qp063oa},
  urldate = {2025-01-21},
  langid = {english}
}

@article{breznau_does_2021,
  title = {Does {{Sociology Need Open Science}}?},
  author = {Breznau, Nate},
  year = {2021},
  month = mar,
  journal = {Societies},
  volume = {11},
  number = {1},
  pages = {9},
  publisher = {Multidisciplinary Digital Publishing Institute},
  doi = {10.3390/soc11010009},
  urldate = {2021-06-05},
  abstract = {Reliability, transparency, and ethical crises pushed many social science disciplines toward dramatic changes, in particular psychology and more recently political science. This paper discusses why sociology should also change. It reviews sociology as a discipline through the lens of current practices, definitions of sociology, positions of sociological associations, and a brief consideration of the arguments of three highly influential yet epistemologically diverse sociologists: Weber, Merton, and Habermas. It is a general overview for students and sociologists to quickly familiarize themselves with the state of sociology or explore the idea of open science and its relevance to their discipline.},
  langid = {english},
  keywords = {crisis of science,Habermas,Merton,open science,p-hacking,publication bias,replication,research ethics,revisado,science community,sociology legitimation,transparency,Weber}
}

@article{chopik_relationship_2020,
  title = {Relationship Science and the Credibility Revolution: {{An}} Introduction to the First Part of the Special Issue},
  shorttitle = {Relationship Science and the Credibility Revolution},
  author = {Chopik, William J. and Chartier, Christopher R. and Campbell, Lorne and Donnellan, M. Brent},
  year = {2020},
  month = mar,
  journal = {Personal Relationships},
  volume = {27},
  number = {1},
  pages = {132--137},
  publisher = {Wiley},
  address = {Hoboken},
  issn = {1350-4126},
  doi = {10.1111/pere.12312},
  urldate = {2021-08-17},
  abstract = {In the past 10 years, the field of relationship science-like many other fields-has been exposed to dramatic changes in how scientists approach the research process. Relationship science has been at the forefront of many recent changes in the field, whether it be high profile replication attempts or broader discussions about how to increase rigor and reproducibility. A major goal of this special issue was to provide an opportunity for relationship scientists to engage with these issues and reforms. The first four articles in this special issue represent a sampling of different approaches relationship researchers have used to enhance the credibility of their work.},
  langid = {english},
  keywords = {credibility revolution,history,incentives,increase,personal relationships,registered reports,registered-reports,replication,special issue,truth}
}

@article{christensen_study_2019,
  title = {A Study of the Impact of Data Sharing on Article Citations Using Journal Policies as a Natural Experiment},
  author = {Christensen, Garret and Dafoe, Allan and Miguel, Edward and Moore, Don A. and Rose, Andrew K.},
  editor = {Naudet, Florian},
  year = {2019},
  month = dec,
  journal = {PLOS ONE},
  volume = {14},
  number = {12},
  pages = {e0225883},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0225883},
  urldate = {2025-06-19},
  langid = {english}
}

@book{creswell_designing_2018,
  title = {Designing and {{Conducting Mixed Methods Research}}},
  author = {Creswell, John W and Plano Clark, Vicki L},
  year = {2018},
  publisher = {SAGE Publications},
  langid = {english}
}

@misc{dallmeier-tiessen_highlights_2011,
  title = {Highlights from the {{SOAP}} Project Survey. {{What Scientists Think}} about {{Open Access Publishing}}},
  author = {{Dallmeier-Tiessen}, Suenje and Darby, Robert and Goerner, Bettina and Hyppoelae, Jenni and {Igo-Kemenes}, Peter and Kahn, Deborah and Lambert, Simon and Lengenfelder, Anja and Leonard, Chris and Mele, Salvatore and Nowicka, Malgorzata and Polydoratou, Panayiota and Ross, David and {Ruiz-Perez}, Sergio and Schimmer, Ralf and Swaisland, Mark and van der Stelt, Wim},
  year = {2011},
  month = jan,
  number = {arXiv:1101.5260},
  eprint = {1101.5260},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1101.5260},
  urldate = {2025-06-19},
  abstract = {The SOAP (Study of Open Access Publishing) project has run a large-scale survey of the attitudes of researchers on, and the experiences with, open access publishing. Around forty thousands answers were collected across disciplines and around the world, showing an overwhelming support for the idea of open access, while highlighting funding and (perceived) quality as the main barriers to publishing in open access journals. This article serves as an introduction to the survey and presents this and other highlights from a preliminary analysis of the survey responses. To allow a maximal re-use of the information collected by this survey, the data are hereby released under a CC0 waiver, so to allow libraries, publishers, funding agencies and academics to further analyse risks and opportunities, drivers and barriers, in the transition to open access publishing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Digital Libraries}
}

@article{delikoura_open_2021,
  title = {Open {{Research Data}} and {{Open Peer Review}}: {{Perceptions}} of a {{Medical}} and {{Health Sciences Community}} in {{Greece}}},
  shorttitle = {Open {{Research Data}} and {{Open Peer Review}}},
  author = {Delikoura, Eirini and Kouis, Dimitrios},
  year = {2021},
  month = mar,
  journal = {Publications},
  volume = {9},
  number = {2},
  pages = {14},
  issn = {2304-6775},
  doi = {10.3390/publications9020014},
  urldate = {2021-12-05},
  abstract = {Recently significant initiatives have been launched for the dissemination of Open Access as part of the Open Science movement. Nevertheless, two other major pillars of Open Science such as Open Research Data (ORD) and Open Peer Review (OPR) are still in an early stage of development among the communities of researchers and stakeholders. The present study sought to unveil the perceptions of a medical and health sciences community about these issues. Through the investigation of researchers` attitudes, valuable conclusions can be drawn, especially in the field of medicine and health sciences, where an explosive growth of scientific publishing exists. A quantitative survey was conducted based on a structured questionnaire, with 179 valid responses. The participants in the survey agreed with the Open Peer Review principles. However, they ignored basic terms like FAIR (Findable, Accessible, Interoperable, and Reusable) and appeared incentivized to permit the exploitation of their data. Regarding Open Peer Review (OPR), participants expressed their agreement, implying their support for a trustworthy evaluation system. Conclusively, researchers need to receive proper training for both Open Research Data principles and Open Peer Review processes which combined with a reformed evaluation system will enable them to take full advantage of the opportunities that arise from the new scholarly publishing and communication landscape.},
  langid = {english}
}

@article{enke_user_2012,
  title = {The User's View on Biodiversity Data Sharing --- {{Investigating}} Facts of Acceptance and Requirements to Realize a Sustainable Use of Research Data ---},
  author = {Enke, Neela and Thessen, Anne and Bach, Kerstin and Bendix, J{\"o}rg and Seeger, Bernhard and Gemeinholzer, Birgit},
  year = {2012},
  month = sep,
  journal = {Ecological Informatics},
  volume = {11},
  pages = {25--33},
  issn = {15749541},
  doi = {10.1016/j.ecoinf.2012.03.004},
  urldate = {2021-12-16},
  langid = {english}
}

@incollection{fecher_open_2014,
  title = {Open {{Science}}: {{One Term}}, {{Five Schools}} of {{Thought}}},
  shorttitle = {Open {{Science}}},
  booktitle = {Opening {{Science}}},
  author = {Fecher, Benedikt and Friesike, Sascha},
  editor = {Bartling, S{\"o}nke and Friesike, Sascha},
  year = {2014},
  pages = {17--47},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-00026-8_2},
  urldate = {2025-06-19},
  isbn = {978-3-319-00025-1 978-3-319-00026-8},
  langid = {english}
}

@article{gross_landscapes_2015,
  title = {Landscapes of {{Research}}: {{Perceptions}} of {{Open Access}} ({{OA}}) {{Publishing}} in the {{Arts}} and {{Humanities}}},
  shorttitle = {Landscapes of {{Research}}},
  author = {Gross, Julia and Ryan, John},
  year = {2015},
  month = apr,
  journal = {Publications},
  volume = {3},
  number = {2},
  pages = {65--88},
  issn = {2304-6775},
  doi = {10.3390/publications3020065},
  urldate = {2021-12-14},
  langid = {english}
}

@article{hail_reproducibility_2020,
  title = {Reproducibility in {{Accounting Research}}: {{Views}} of the {{Research Community}}},
  shorttitle = {Reproducibility in {{Accounting Research}}},
  author = {Hail, Luzi and Lang, Mark and Leuz, Christian},
  year = {2020},
  month = may,
  journal = {Journal of Accounting Research},
  volume = {58},
  number = {2},
  pages = {519--543},
  issn = {0021-8456, 1475-679X},
  doi = {10.1111/1475-679X.12305},
  urldate = {2021-12-03},
  langid = {english}
}

@article{hardwicke_empirical_2020,
  title = {An Empirical Assessment of Transparency and Reproducibility-Related Research Practices in the Social Sciences (2014--2017)},
  author = {Hardwicke, Tom E. and Wallach, Joshua D. and Kidwell, Mallory C. and Bendixen, Theiss and Cr{\"u}well, Sophia and Ioannidis, John P. A.},
  year = {2020},
  month = feb,
  journal = {Royal Society Open Science},
  volume = {7},
  number = {2},
  pages = {190806},
  issn = {2054-5703},
  doi = {10.1098/rsos.190806},
  urldate = {2025-06-19},
  abstract = {Serious concerns about research quality have catalysed a number of reform initiatives intended to improve transparency and reproducibility and thus facilitate self-correction, increase efficiency and enhance research credibility. Meta-research has evaluated the merits of some individual initiatives; however, this may not capture broader trends reflecting the cumulative contribution of these efforts. In this study, we manually examined a random sample of 250 articles in order to estimate the prevalence of a range of transparency and reproducibility-related indicators in the social sciences literature published between 2014 and 2017. Few articles indicated availability of materials (16/151, 11\% [95\% confidence interval, 7\% to 16\%]), protocols (0/156, 0\% [0\% to 1\%]), raw data (11/156, 7\% [2\% to 13\%]) or analysis scripts (2/156, 1\% [0\% to 3\%]), and no studies were pre-registered (0/156, 0\% [0\% to 1\%]). Some articles explicitly disclosed funding sources (or lack of; 74/236, 31\% [25\% to 37\%]) and some declared no conflicts of interest (36/236, 15\% [11\% to 20\%]). Replication studies were rare (2/156, 1\% [0\% to 3\%]). Few studies were included in evidence synthesis via systematic review (17/151, 11\% [7\% to 16\%]) or meta-analysis (2/151, 1\% [0\% to 3\%]). Less than half the articles were publicly available (101/250, 40\% [34\% to 47\%]). Minimal adoption of transparency and reproducibility-related research practices could be undermining the credibility and efficiency of social science research. The present study establishes a baseline that can be revisited in the future to assess progress.},
  langid = {english}
}

@article{head_extent_2015,
  title = {The {{Extent}} and {{Consequences}} of {{P-Hacking}} in {{Science}}},
  author = {Head, Megan L. and Holman, Luke and Lanfear, Rob and Kahn, Andrew T. and Jennions, Michael D.},
  year = {2015},
  month = mar,
  journal = {Plos Biology},
  volume = {13},
  number = {3},
  pages = {e1002106},
  publisher = {Public Library Science},
  address = {San Francisco},
  issn = {1544-9173},
  doi = {10.1371/journal.pbio.1002106},
  urldate = {2021-08-22},
  abstract = {A focus on novel, confirmatory, and statistically significant results leads to substantial bias in the scientific literature. One type of bias, known as "p-hacking," occurs when researchers collect or select data or statistical analyses until nonsignificant results become significant. Here, we use text-mining to demonstrate that p-hacking is widespread throughout science. We then illustrate how one can test for p-hacking when performing a meta-analysis and show that, while p-hacking is probably common, its effect seems to be weak relative to the real effect sizes being measured. This result suggests that p-hacking probably does not drastically alter scientific consensuses drawn from meta-analyses.},
  langid = {english},
  keywords = {clinical-research,competition,confidence,extra-pair paternity,false discovery rate,metaanalysis,operational sex-ratio,publication bias,replication,wise false}
}

@article{hodonu-wusu_malasyan_2020,
  title = {Malasyan Researches on Open Data. {{The}} First National Surven on Awareness, Practices and Attitudes},
  author = {{Hodonu-wusu} and {Noorhidawati} and {Abrizah}},
  year = {2020},
  journal = {Malaysian Journal of Library \& Information Science},
  volume = {25},
  number = {2},
  pages = {1--20},
  doi = {10.22452/mjlis.vol25no2.1}
}

@article{hollenbeck_harking_2017,
  title = {Harking, {{Sharking}}, and {{Tharking}}: {{Making}} the {{Case}} for {{Post Hoc Analysis}} of {{Scientific Data}}},
  shorttitle = {Harking, {{Sharking}}, and {{Tharking}}},
  author = {Hollenbeck, John R. and Wright, Patrick M.},
  year = {2017},
  month = jan,
  journal = {Journal of Management},
  volume = {43},
  number = {1},
  pages = {5--18},
  publisher = {SAGE Publications Inc},
  issn = {0149-2063},
  doi = {10.1177/0149206316679487},
  urldate = {2021-07-01},
  abstract = {In this editorial we discuss the problems associated with HARKing (Hypothesizing After Results Are Known) and draw a distinction between Sharking (Secretly HARKing in the Introduction section) and Tharking (Transparently HARKing in the Discussion section). Although there is never any justification for the process of Sharking, we argue that Tharking can promote the effectiveness and efficiency of both scientific inquiry and cumulative knowledge creation. We argue that the discussion sections of all empirical papers should include a subsection that reports post hoc exploratory data analysis. We explain how authors, reviewers, and editors can best leverage post hoc analyses in the spirit of scientific discovery in a way that does not bias parameter estimates and recognizes the lack of definitiveness associated with any single study or any single replication. We also discuss why the failure to Thark in high-stakes contexts where data is scarce and costly may also be unethical.},
  langid = {english},
  keywords = {macro topics,micro topics,philosophy of science,practices,research design,research methods,statistical methods}
}

@article{kerr_harking_1998,
  title = {{{HARKing}}: {{Hypothesizing After}} the {{Results}} Are {{Known}}},
  shorttitle = {{{HARKing}}},
  author = {Kerr, Norbert L.},
  year = {1998},
  month = aug,
  journal = {Personality and Social Psychology Review},
  volume = {2},
  number = {3},
  pages = {196--217},
  publisher = {SAGE Publications Inc},
  issn = {1088-8683},
  doi = {10.1207/s15327957pspr0203_4},
  urldate = {2021-08-23},
  abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as if it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing's costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
  langid = {english}
}

@article{knudtson_survey_2019,
  title = {Survey on {{Scientific Shared Resource Rigor}} and {{Reproducibility}}},
  author = {Knudtson, Kevin L. and Carnahan, Robert H. and {Hegstad-Davies}, Rebecca L. and Fisher, Nancy C. and Hicks, Belynda and Lopez, Peter A. and Meyn, Susan M. and Mische, Sheenah M. and {Weis-Garcia}, Frances and White, Lisa D. and {Sol-Church}, Katia},
  year = {2019},
  month = sep,
  journal = {Journal of Biomolecular Techniques : JBT},
  volume = {30},
  number = {3},
  pages = {36--44},
  issn = {1524-0215, 1943-4731},
  doi = {10.7171/jbt.19-3003-001},
  urldate = {2022-01-12}
}

@article{lacey_open_2020,
  title = {Open Science for Responsible Innovation in {{Australia}}: {{Understanding}} the Expectations and Priorities of Scientists and Researchers},
  shorttitle = {Open Science for Responsible Innovation in {{Australia}}},
  author = {Lacey, Justine and Coates, Rebecca and Herington, Matthew},
  year = {2020},
  month = sep,
  journal = {Journal of Responsible Innovation},
  volume = {7},
  number = {3},
  pages = {427--449},
  issn = {2329-9460, 2329-9037},
  doi = {10.1080/23299460.2020.1800969},
  urldate = {2021-11-29},
  langid = {english}
}

@book{lewins_using_2007,
  title = {Using {{Software}} in {{Qualitative Research}}},
  author = {Lewins, Ann and Silver, Christina},
  year = {2007},
  publisher = {SAGE Publications, Ltd},
  address = {1 Oliver's Yard,~55 City Road,~London~England~EC1Y 1SP~United Kingdom},
  doi = {10.4135/9780857025012},
  urldate = {2025-01-21},
  isbn = {978-0-7619-4923-7 978-0-85702-501-2}
}

@article{ljubenkovic_survey_2021,
  title = {Survey on the {{Research Misconduct}} and {{Questionable Research Practices}} of {{Medical Students}}, {{PhD Students}}, and {{Supervisors}} at the {{Zagreb School}} of {{Medicine}} in {{Croatia}}},
  author = {Ljubenkovi{\'c}, Ana Marija and Borove{\v c}ki, Ana and {\'C}urkovi{\'c}, Marko and Hofmann, Bj{\o}rn and Holm, S{\o}ren},
  year = {2021},
  month = oct,
  journal = {Journal of Empirical Research on Human Research Ethics},
  volume = {16},
  number = {4},
  pages = {435--449},
  issn = {1556-2646, 1556-2654},
  doi = {10.1177/15562646211033727},
  urldate = {2021-11-23},
  abstract = {This cross-sectional study evaluates the knowledge, attitudes, experiences, and behavior of final year medical students, PhD students, and supervisors at the School of Medicine of the University of Zagreb in relation to research misconduct, questionable research practices, and the research environment. The overall response rate was 36.4\% (68\%--100\% for the paper survey and 8\%--15\% for the online surveys). The analysis reveals statistically significant differences in attitude scores between PhD students and supervisors, the latter having attitudes more in concordance with accepted norms. The results overall show a nonnegligible incidence of self-reported misconduct and questionable research practices, as well as some problematic attitudes towards misconduct and questionable research practices. The incidence of problematic authorship practices was particularly high. The research environment was evaluated as being mostly supportive of research integrity.},
  langid = {english}
}

@article{lopezcardenas_percepciones_2021,
  title = {Percepciones y Pr{\'a}cticas de La Ciencia Abierta En {{Venezuela}}. {{Un}} Acercamiento a La Cuesti{\'o}n},
  author = {Lopez Cardenas, Maria and {Cubero-Castillo}, Enrique},
  year = {2021},
  month = jan,
  journal = {Observador del Conocimiento},
  volume = {5},
  number = {4 -diciemb},
  urldate = {2021-11-12},
  abstract = {La Ciencia Abierta naci{\'o} como un movimiento interno dentro de la ciencia, que demandaba abrir los espacios tradicionales de la producci{\'o}n de conocimientos. La pandemia de la COVID-19 oblig{\'o} a muchos centros de investigaciones, laboratorios e investigadores a adoptar las formas propuestas por este movimiento, con el fin de responder m{\'a}s r{\'a}pido a las demandas de la sociedad a nivel global. El impulso que se le ha dado a la Ciencia Abierta durante esta emergencia sanitaria, ha puesto sobre el tapete la discusi{\'o}n y la apuesta por reglamentar las normas a nivel internacional para asegurar una transici{\'o}n equilibrada. Es por ello que diversos organismos nacionales, como el caso de ONCTI, han adelantado iniciativas de consulta para conocer la percepci{\'o}n de los cient{\'i}ficos en torno a este nuevo paradigma. Producto de estas consultas, se han generado una serie de estad{\'i}sticas que permiten sondear el estado de la cuesti{\'o}n. En este trabajo analizamos algunas de ellas, encontrando que una parte importante de los encuestados no est{\'a} familiarizada sobre la realidad de la aplicaci{\'o}n de la Ciencia Abierta a nivel nacional, o la asocia con iniciativas y pr{\'a}cticas propias de la ciencia tradicional. Un ejemplo son las nociones de ``transferencia de conocimiento hacia las comunidades'' o ``divulgaci{\'o}n de la ciencia'', que implican una visi{\'o}n ofertista y lineal de la misma. Es importante considerar estas asociaciones al momento de formular una pol{\'i}tica de Ciencia Abierta a nivel nacional.},
  chapter = {Art{\'i}culos}
}

@article{mauthner_open_2013,
  title = {Open {{Access Digital Data Sharing}}: {{Principles}}, {{Policies}} and {{Practices}}},
  shorttitle = {Open {{Access Digital Data Sharing}}},
  author = {Mauthner, Natasha Susan and Parry, Odette},
  year = {2013},
  month = jan,
  journal = {Social Epistemology},
  volume = {27},
  number = {1},
  pages = {47--67},
  issn = {0269-1728, 1464-5297},
  doi = {10.1080/02691728.2012.760663},
  urldate = {2025-06-19},
  langid = {english}
}

@article{narayan_scholarly_2018,
  title = {Scholarly {{Communication Practices}} in {{Humanities}} and {{Social Sciences}}: {{A Study}} of {{Researchers}}' {{Attitudes}} and {{Awareness}} of {{Open Access}}},
  shorttitle = {Scholarly {{Communication Practices}} in {{Humanities}} and {{Social Sciences}}},
  author = {Narayan, Bhuva and Luca, Edward J. and Tiffen, Belinda and England, Ashley and Booth, Mal and Boateng, Henry},
  year = {2018},
  month = dec,
  journal = {Open Information Science},
  volume = {2},
  number = {1},
  pages = {168--180},
  issn = {2451-1781},
  doi = {10.1515/opis-2018-0013},
  urldate = {2025-06-19},
  abstract = {Abstract             This paper examines issues relating to the perceptions and adoption of open access (OA) and institutional repositories. Using a survey research design, we collected data from academics and other researchers in the humanities, arts and social sciences (HASS) at a university in Australia. We looked at factors influencing choice of publishers and journal outlets, as well as the use of social media and nontraditional channels for scholarly communication. We used an online questionnaire to collect data and used descriptive statistics to analyse the data. Our findings suggest that researchers are highly influenced by traditional measures of quality, such as journal impact factor, and are less concerned with making their work more findable and promoting it through social media. This highlights a disconnect between researchers' desired outcomes and the efforts that they put in toward the same. Our findings also suggest that institutional policies have the potential to increase OA awareness and adoption. This study contributes to the growing literature on scholarly communication by offering evidence from the HASS field, where limited studies have been conducted. Based on the findings, we recommend that academic librarians engage with faculty through outreach and workshops to change perceptions of OA and the institutional repository.},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0}
}

@article{nosek_preregistration_2018,
  title = {The Preregistration Revolution},
  author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
  year = {2018},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {11},
  pages = {2600--2606},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708274114},
  urldate = {2025-06-19},
  abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes---a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
  langid = {english}
}

@article{nosek_preregistration_2019,
  title = {Preregistration {{Is Hard}}, {{And Worthwhile}}},
  author = {Nosek, Brian A. and Beck, Emorie D. and Campbell, Lorne and Flake, Jessica K. and Hardwicke, Tom E. and Mellor, David T. and Van 'T Veer, Anna E. and Vazire, Simine},
  year = {2019},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {10},
  pages = {815--818},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.07.009},
  urldate = {2025-06-19},
  langid = {english}
}

@article{nosek_promoting_2015,
  title = {Promoting an Open Research Culture},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and {Mayo-Wilson}, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  year = {2015},
  month = jun,
  journal = {Science},
  volume = {348},
  number = {6242},
  pages = {1422--1425},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  urldate = {2021-06-04},
  abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility Author guidelines for journals could help to promote transparency, openness, and reproducibility},
  chapter = {Policy Forum},
  copyright = {Copyright {\copyright} 2015, American Association for the Advancement of Science},
  langid = {english},
  pmid = {26113702},
  keywords = {revisado}
}

@article{nowell_thematic_2017,
  title = {Thematic {{Analysis}}: {{Striving}} to {{Meet}} the {{Trustworthiness Criteria}}},
  shorttitle = {Thematic {{Analysis}}},
  author = {Nowell, Lorelli S. and Norris, Jill M. and White, Deborah E. and Moules, Nancy J.},
  year = {2017},
  month = dec,
  journal = {International Journal of Qualitative Methods},
  volume = {16},
  number = {1},
  pages = {1609406917733847},
  issn = {1609-4069, 1609-4069},
  doi = {10.1177/1609406917733847},
  urldate = {2025-01-21},
  abstract = {As qualitative research becomes increasingly recognized and valued, it is imperative that it is conducted in a rigorous and methodical manner to yield meaningful and useful results. To be accepted as trustworthy, qualitative researchers must demonstrate that data analysis has been conducted in a precise, consistent, and exhaustive manner through recording, systematizing, and disclosing the methods of analysis with enough detail to enable the reader to determine whether the process is credible. Although there are numerous examples of how to conduct qualitative research, few sophisticated tools are available to researchers for conducting a rigorous and relevant thematic analysis. The purpose of this article is to guide researchers using thematic analysis as a research method. We offer personal insights and practical examples, while exploring issues of rigor and trustworthiness. The process of conducting a thematic analysis is illustrated through the presentation of an auditable decision trail, guiding interpreting and representing textual data. We detail our step-by-step approach to exploring the effectiveness of strategic clinical networks in Alberta, Canada, in our mixed methods case study. This article contributes a purposeful approach to thematic analysis in order to systematize and increase the traceability and verification of the analysis.},
  langid = {english}
}

@article{pardomartinez_knowledge_2018,
  title = {Knowledge and {{Perceptions}} of {{Open Science}} among {{Researchers}}---{{A Case Study}} for {{Colombia}}},
  author = {Pardo Mart{\'i}nez, Clara and Poveda, Alexander},
  year = {2018},
  month = nov,
  journal = {Information-an International Interdisciplinary Journal},
  volume = {9},
  number = {11},
  pages = {292},
  issn = {2078-2489},
  doi = {10.3390/info9110292},
  urldate = {2021-11-11},
  abstract = {Open science can provide researchers diverse opportunities to collaborate, disseminate their research results, generate important impacts in the scientific community, and engage in effective and efficient science for the benefit of society. This study seeks to analyse and evaluate researchers' knowledge of open science in Colombia using a survey to determine adequate instruments with which to improve research in the framework of open science. The aim of the study is to determine researchers' current awareness of open science by considering demographic characteristics to analyse their attitudes, values, and information habits as well as the levels of institutionalism and social appropriation of open science. A representative sample of Colombian researchers was selected from the National Research System. An anonymous online survey consisting of 34 questions was sent to all professors and researchers at Colombian universities and research institutes. Sampling was random and stratified, which allowed for a representative sample of different categories of researchers, and principal component analysis (PCA) was used for the sample design. A total of 1042 responses were received, with a 95\% confidence level and a margin of error of 3\%. The majority of respondents knew about open science, especially in relation to open science tools (software, repositories, and networks) and open data. Researchers consider open science to be positively impacted by factors such as the rise of digital technologies, the search for new forms of collaboration, the greater availability of open data and information, and public demand for better and more effective science. In contrast, a lack of resources to develop research activities within the open science approach and the limited integration between traditional and open science are identified as the most important barriers to its use in research. These results are important for building adequate open science policy in Colombia.},
  langid = {english}
}

@article{peng_reproducibility_2015,
  title = {The Reproducibility Crisis in Science: {{A}} Statistical Counterattack},
  shorttitle = {The Reproducibility Crisis in Science},
  author = {Peng, Roger},
  year = {2015},
  journal = {Significance},
  volume = {12},
  number = {3},
  pages = {30--32},
  issn = {1740-9713},
  doi = {10.1111/j.1740-9713.2015.00827.x},
  urldate = {2021-06-14},
  abstract = {More people have more access to data than ever before. But a comparative lack of analytical skills has resulted in scientific findings that are neither replicable nor reproducible. It is time to invest in statistics education, says Roger Peng},
  copyright = {{\copyright} 2015 The Royal Statistical Society},
  langid = {english},
  keywords = {crisis}
}

@article{ramos_campo_2008,
  title = {El {{Campo}} de Las {{Ciencias Sociales}} En {{Chile}}: {\textquestiondown}{{Convergencia}} Disciplinar En La Construcci{\'o}n Del Objeto de Estudio?},
  shorttitle = {El {{Campo}} de Las {{Ciencias Sociales}} En {{Chile}}},
  author = {Ramos, C. and Canales, A. and Palestini, S.},
  year = {2008},
  journal = {Cinta de Moebio},
  number = {33},
  urldate = {2025-02-18}
}

@article{rodriguez_awareness_2014,
  title = {Awareness and {{Attitudes}} about {{Open Access Publishing}}: {{A Glance}} at {{Generational Differences}}},
  shorttitle = {Awareness and {{Attitudes}} about {{Open Access Publishing}}},
  author = {Rodriguez, Julia E.},
  year = {2014},
  month = nov,
  journal = {The Journal of Academic Librarianship},
  volume = {40},
  number = {6},
  pages = {604--610},
  issn = {00991333},
  doi = {10.1016/j.acalib.2014.07.013},
  urldate = {2021-12-01},
  langid = {english}
}

@article{rowley_academics_2017,
  title = {Academics' Behaviors and Attitudes towards Open Access Publishing in Scholarly Journals},
  author = {Rowley, Jennifer and Johnson, Frances and Sbaffi, Laura and Frass, Will and Devine, Elaine},
  year = {2017},
  month = may,
  journal = {Journal of the Association for Information Science and Technology},
  volume = {68},
  number = {5},
  pages = {1201--1211},
  issn = {23301635},
  doi = {10.1002/asi.23710},
  urldate = {2021-12-16},
  langid = {english}
}

@article{sturmer_earlycareer_2017,
  title = {Early-{{Career Researchers}}' {{Perceptions}} of the {{Prevalence}} of {{Questionable Research Practices}}, {{Potential Causes}}, and {{Open Science}}},
  author = {St{\"u}rmer, Stefan and Oeberst, Aileen and Tr{\"o}tschel, Roman and Decker, Oliver},
  year = {2017},
  month = nov,
  journal = {Social Psychology},
  volume = {48},
  number = {6},
  pages = {365--371},
  issn = {1864-9335, 2151-2590},
  doi = {10.1027/1864-9335/a000324},
  urldate = {2021-11-23},
  abstract = {Abstract. Young researchers of today will shape the field in the future. In light of current debates about social psychology's research culture, this exploratory survey assessed early-career researchers' beliefs (N = 88) about the prevalence of questionable research practices (QRPs), potential causes, and open science as a possible solution. While there was relative consensus that outright fraud is an exception, a majority of participants believed that some QRPs are moderately to highly prevalent what they attributed primarily to academic incentive structures. A majority of participants felt that open science is necessary to improve research practice. They indicated to consider some open science recommendations in the future, but they also indicated some reluctance. Limitation and implications of these findings are discussed.},
  langid = {english}
}

@article{vandeneynden_sowing_2014,
  title = {Sowing the Seed: {{Incentives}} and Motivations for Sharing Research Data, a Researcher's Perspective},
  author = {{Van den Eynden}, Veerle and Bishop, Libby},
  year = {2014},
  journal = {Knowledge Exchange Report},
  doi = {https://repository.jisc.ac.uk/5662/1/KE_report-incentives-for-sharing-researchdata.pdf},
  abstract = {This study, commissioned by Knowledge Exchange, has gathered evidence, examples and opinions on current and future incentives for research data sharing from the researcher's point of view, in order to provide recommendations for policy and practice development on how best to incentivise data access and reuse.}
}

@article{zhu_openaccess_2020,
  title = {Open-Access Policy and Data-Sharing Practice in {{UK}} Academia},
  author = {Zhu, Yimei},
  year = {2020},
  month = feb,
  journal = {Journal of Information Science},
  volume = {46},
  number = {1},
  pages = {41--52},
  issn = {0165-5515, 1741-6485},
  doi = {10.1177/0165551518823174},
  urldate = {2021-11-23},
  abstract = {Data sharing can be defined as the release of research data that can be used by others. With the recent open-science movement, there has been a call for free access to data, tools and methods in academia. In recent years, subject-based and institutional repositories and data centres have emerged along with online publishing. Many scientific records, including published articles and data, have been made available via new platforms. In the United Kingdom, most major research funders had a data policy and require researchers to include a `data-sharing plan' when applying for funding. However, there are a number of barriers to the full-scale adoption of data sharing. Those barriers are not only technical, but also psychological and social. A survey was conducted with over 1800 UK-based academics to explore the extent of support of data sharing and the characteristics and factors associated with data-sharing practice. It found that while most academics recognised the importance of sharing research data, most of them had never shared or reused research data. There were differences in the extent of data sharing between different gender, academic disciplines, age and seniority. It also found that the awareness of Research Council UK's (RCUK) Open-Access (OA) policy, experience of Gold and Green OA publishing, attitudes towards the importance of data sharing and experience of using secondary data were associated with the practice of data sharing. A small group of researchers used social media such as Twitter, blogs and Facebook to promote the research data they had shared online. Our findings contribute to the knowledge and understanding of open science and offer recommendations to academic institutions, journals and funding agencies.},
  langid = {english}
}
